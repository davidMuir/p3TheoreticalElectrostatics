
\documentclass[aps,twocolumn,pre,nofootinbib,10pt]{revtex4-1}

\usepackage{auto-pst-pdf}
\usepackage{amsmath,amssymb,amsfonts,amsthm}
\usepackage{graphicx}
\usepackage{bbm}
\graphicspath{{../plots/}}


\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Useful symbols and definitions that may save time
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\breite}{1.0} %  for twocolumn


\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}

\newcommand{\be}{\begin{equation}}
\newcommand{\ee}{\end{equation}}

\newcommand{\bea}{\begin{eqnarray}}
\newcommand{\eea}{\end{eqnarray}}

\newcommand{\Reals}{\mathbb{R}}     % Real
\newcommand{\Int}{\mathbb{Z}}       % Integer
\newcommand{\Com}{\mathbb{C}}       % Complex 
\newcommand{\Nat}{\mathbb{N}}       % Natural 


\newcommand{\id}{\mathbbm{1}}    

\newcommand{\Real}{\mathop{\mathrm{Re}}}
\newcommand{\Imag}{\mathop{\mathrm{Im}}}

\def\O{\mbox{$\mathcal{O}$}}    
\def\F{\mathcal{F}}			
\def\sgn{\text{sgn}}

\newcommand{\dw}{\ensuremath{\Delta}} %I think I have most we need but will add any if needed.
\newcommand{\wbp}{\ensuremath{\omega_0}}
\newcommand{\dv}{\ensuremath{\delta}}
\newcommand{\vbp}{\ensuremath{\nu_0}}
\newcommand{\vplus}{\ensuremath{\nu_{+}}}
\newcommand{\vminus}{\ensuremath{\nu_{-}}}
\newcommand{\wplus}{\ensuremath{\omega_{+}}}
\newcommand{\wminus}{\ensuremath{\omega_{-}}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%Title of paper (I know it isn't very creative but it isn't supposed to be. We can definitely discuss this! 
\title{Numerical solutions to the Laplace Equation applied to electrostatic fields}


%Us
\author{Karl Nordstorm}

\author{David Muir}

\author{Julia Kettle}

\author{John Maccorquodale}

\author{Jevgeny Klochan}

\author{Stephen Shepstone}


\affiliation{University Of Glasgow}

\date{\today}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%ABSTRACT
\begin{abstract}

Abstract... 
  
\end{abstract}


%FINISH TITLE
\maketitle


%INTRODUCTION

\section{Introduction \label{sec:int}}

Intro...


 

%THEORY AND ALGORITHMS
\section{Theory \label{sec:the}}

\subsection{Solving the Laplace Equation in two dimensions}
We'll solve Laplace's Equation in polar coordinates for the scalar field $\Phi(r, \theta)$:
\[ \left( r \Phi_r \right)_r + \frac{1}{r} \left(\Phi_\theta \right)_\theta = 0 \]
Assuming we can separate variables such that $\Phi(r, \theta) = R(r)\Theta(\theta)$:
\begin{gather*}
 \Phi_r = R'\Theta, \Phi_\theta = R\Theta' \Rightarrow \\
 (rR'\Theta)_r + \frac{1}{r}(R\Theta')_\theta = 0 \Leftrightarrow \\
 R'\Theta + rR''\Theta + \frac{1}{r}R\Theta'' = 0 \Leftrightarrow \\
 \frac{rR' + r^2 R''}{R} = \frac{- \Theta''}{\Theta} \Leftrightarrow \\
 \frac{r(rR')'}{R} = \frac{- \Theta''}{\Theta}
\end{gather*}

Set both sides equal to $\lambda^2$:
\[ (A) \hspace{0.5cm} \frac{r(rR')'}{R} = \lambda^2, \hspace{1cm} (B) \hspace{0.5cm} \frac{- \Theta''}{\Theta} = \lambda^2 \]
Solve the two differential equations separately, assuming at first that $\lambda \neq 0$. 
For (A), use a solution of the form $R(r) = \gamma r^\alpha$:
\begin{gather*}
 R' = \gamma \alpha r^{\alpha - 1} \Rightarrow \\
 \frac{r(r\gamma \alpha r^{\alpha - 1})'}{\gamma r^\alpha} = \lambda^2 \Leftrightarrow \\
 \alpha^2 \frac{\gamma r r^{\alpha - 1}}{\gamma r^\alpha} = \lambda^2 \Leftrightarrow \\
 \alpha^2 = \lambda^2 \Rightarrow \alpha = \pm \lambda 
\end{gather*}
For (B), we have $\Theta'' + \lambda^2 \Theta = 0$, so the general form of the solution is:
\[ \Theta(\theta) = A \cos(\lambda \theta) + B \sin(\lambda \theta) \]
Since $\Theta(0) = \Theta(2\pi)$ we know that $\lambda \in \mathbb{N}$ (or, more generally,
that $\lambda \in \mathbb{Z}$ but due to the symmetry in $\cos$ and $\sin$ that information can be encoded into $A$ and $B$).
When $\lambda = 0$ we can in both cases integrate to find the solutions:
\[ (A) \hspace{0.5cm} R(r) = c_1 \ln r + c_2,\hspace{1cm} (B)\hspace{0.5cm} \Theta(\theta) = c_3 \theta + c_4 \]
Since the Laplace Equation is linear, we can add the solutions together to get the general solution set:
\begin{gather*}
 \Phi(r, \theta) = R(r)\Theta(\theta)_{\lambda = 0} + R(r)\Theta(\theta)_{\lambda \in \mathbb{N}} = \\
 (c_1 \ln r + c_2)(c_3 \theta + c_4) + \\
\sum_{n \in \mathbb{N}} (\gamma_{1n} r^n + \gamma_{2n} r^{-n})
\big[A \cos(n \theta) + B \sin(n \theta) \big] 
\end{gather*}

\subsection{Particular solution for infinite cylinder in \underline{E} field}
We will add two different solutions together to find the total potential. Let the \underline{E} field be uniform in the x direction
such that $\underline{E} = E_0 \hat{x}$. Since $\underline{E} = - \nabla \Phi$, $\Phi = -E_0 x = -E_0 r \cos\theta$, which is
in the general solution set we defined above.
Our first
boundary condition is then:
\[ \lim_{r \rightarrow \infty} \Phi(r,\theta)_{total} = -E_0 r \cos\theta \]
Next we want to find the field from the cylinder. Let the radius of the cylinder be $R$.
The second boundary condition is that the potential on the surface of the cylinder must be constant,
say $V_0$, so:
\[ (C) \hspace{0.5cm} \Phi(R,\theta)_{total} = -E_0 R \cos\theta + \Phi(R,\theta)_{cylinder} = V_0 \]
$\Phi(r,\theta)_{cylinder}$ must also be in the general solution set defined above. We need a constant so take $c_2 c_4$ from the first
part of the general solution, but discard the
$\ln r$ and $\theta$ terms to keep within the first boundary condition.
From the second part we need to get an expression which lets us fulfill (C), so it is logical to take the $n = 1$ term which has $\cos\theta$:

\begin{gather*}
 \Phi(R,\theta)_{total} = -E_0 R \cos\theta +  c_2 c_4 + \\
(\gamma_{11} R + \gamma_{21} R^{-1}) (A\cos\theta + B \sin\theta) = V_0 
\end{gather*}

Now $B$ must be zero since the sin term would violate the symmetry we require about the x axis, and all that is left is to solve the following equation:

\begin{gather*}
 \Phi(R,\theta)_{total} = -E_0 R \cos\theta + c_2 c_4 + \\
(\gamma_{11} R + \gamma_{21} R^{-1}) A\cos\theta = V_0 \Leftrightarrow \\
 c_2 c_4 - V_0 + R \cos\theta \left( A\gamma_{11} - E_0 + \frac{A\gamma_{21}}{R^2} \right) = 0 
\end{gather*}

Hence set $c_2 c_4 = V_0$, $\gamma_{11} = 0$, and $A\gamma_{21} = E_0 R^2$ to fulfill (C) and get the final solution:
\[ \Phi(r,\theta)_{total} = V_0 + E_0 cos\theta \left( \frac{R^2}{r} - r \right) \]

\subsection{Neutral conductors, local gauge invariance and conservation of charge}

One powerful tool for investigating the validity of our numerical solutions is conservation of charge. Since we are adding neutral conductors to the field, the total integrated field should not change as a result. To understand how it is possible for some numerical solutions to break this fundamental rule we will first consider the electric potential created by a conductor in the field, and then use the power of gauge theory and Noether's Theorem to qualitatively explain the effect.

As the redistribution of charges in the conductor cancels out the electric field inside it, and it has a total charge of 0, we can approximate the charge distribution in the stable state to be similar to an electric dipole where the charges are separated by the length of the conductor in the direction of the field, $l$. This allows us to derive a mathematical expression for the electric potential caused by it:

Consider two charges, $q_+$ and $q_-$, separated by $l$. The total potential at a point $\bar{r}$, at an angle $\theta$ from the normal to $l$, separated from the charges by $r_+$ and $r_-$ can then be written by

\begin{gather*}
V(\bar{r}) = V(r_+) + V(r_-) \\
 = \frac{q_+}{4 \pi \epsilon_0 r_+} + \frac{q_-}{4 \pi \epsilon_0 r_-} \\
 = \frac{q}{4 \pi \epsilon_0}\left( \frac{1}{r_+} - \frac{1}{r_-} \right) \\
 \approx \frac{q}{4 \pi \epsilon_0} \left( \frac{l \sin\theta}{r^2} \right) 
\end{gather*}

Here $r$ is the distance from the midpoint between the two charges to $\bar{r}$. Note that this potential is proportional to $1/r^2$ unlike the electric potential from a point charge, which limits its effective range considerably.

Gauge theory is a powerful tool for analysing fields where the observable quantities are invariant under certain transformations of the field itself \cite{gaugetheory1}. By Noether's two theorems, these symmetries all have corresponding conservation laws: the conserved Noether currents \footnote{Note that there are two theorems to deal with global and local symmetries separately. Global symmetries always lead to conserved currents, while local symmetries do so under certain conditions. See for example \cite{gaugetheory2}.}. The symmetry group of electromagnetism is $U(1)$, and for local gauge invariance requires that its gauge boson is massless and hence gives the force infinite range. Local gauge invariance is here the symmetry that results in conservation of charge. The same symmetry is of course required for the weak force as well, which is why the Higgs mechanism was invented to introduce a way to consistently give mass to the 
$Z$ and $W^{\pm}$ bosons and hence limit the range of the weak force according to experimental observations without breaking gauge invariance \cite{gaugetheory3}. In our case we are interested in gauge theory because it allows us to predict that meaningfully limiting the range of the electromagnetic force by using a finite grid size with the assumption that the conductor won't change the field at the 
boundaries will break conservation of charge. 'Meaningfully' here refers to the fact that the potential from the conductor will tend to 0 quickly as we move further away from it due to the inverse square law, so we can estimate the field to be effectively zero at some finite distance away. This allows us to justify the use of the finite grid sizes we require to make sensible numerical simulations, and gives us a good variable to use for determining how small we can make the grid in comparison to the conductor without creating unphysical solutions: conservation of charge\footnote{Of course many problems with enough symmetry will obey conservation of charge even though the range is effectively limited. This has to be taken into consideration when using charge conservation to measure the required size of the grid.}. The dipole potential calculation also tells us that the required size of the grid varies roughly linearly with the length $l$ of the conductor in the direction of the field, whereas the size in the orthogonal direction to the field is less important.

\subsection{Multiple conductors}
The problem of adding multiple conductors to the same field is that in order to obey charge conservation, they must all take the fields generated by the others into account when deciding their equilibrium potential. In other words, adding one and solving before before adding a new one and keeping the old one constant will give an unphysical result, as the first one will affect the second one but we don't have a mechanism for allowing the second one to affect the first one. The simplest correct way of dealing with this problem is to find solutions for each individual conductor first, averaging them all, and then adding all the conductors into the averaged field at once before solving a last time. This ensures that charge conservation is obeyed and gives the correct physical solution. An alternative solution would be to implement a Stokes integration along the surface of the conductor and using this to calculate the potential of the conductor. This would also allow for time-like evolution of the entire solution, but has so for not been implemented.

\begin{figure}
\includegraphics*[height=\breite \columnwidth,angle=270]{difference.ps} 
\caption{Difference between solutions when two circular conductors are added one at a time and solved simultaneously. A negative value means the solution where conductors are added one at a time is lower than the simultaneous solution. The original uniform field runs from 50 on the left to -50 on the right. An integration over the fields gives a mean charge of about -0.16 in the 'one at a time' solution and effectively 0 in the simultaneous one: a clear indication that charge conservation is violated when adding conductors one at at time.}
\label{fig:difference}
\end{figure}
 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% EXAMPLE FIG BOTH COLUMNS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{figure*}
%\includegraphics*[width= 1.6 \columnwidth]{circle.ps} 
%\caption{Full page figure.}
%\label{fig:Full}
%\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%METHODS- I think algorithms should go here rather than code. Any chunks of code that are necessary for the 
%report should go into the appendix
\section{Numerical Methods \label{sec:met}}

 
\subsection{Finite Difference Method}

\subsubsection{Background Information}

\par\hspace{4mm} In mathematics, there are a number numerical procedures for estimating the solutions to differential equations using finite difference equations to approximate derivatives. These are knowns as finite difference methods. A finite difference is a mathematical expression of the form \(f(x + b) - f(x + a)\). If a finite difference is divided by \((b - a)\), one gets a difference quotient. The estimation of derivatives by finite differences plays a central role in finite difference methods for the numerical solution of differential equations, especially boundary value problems.
\vspace{5mm} \par \indent An essential application of finite differences is in numerical analysis, especially in numerical differential equations, which aim at the numerical solution of ordinary and partial differential equations. The idea is to replace the derivatives appearing in the differential equation by finite differences that approximate them. The resulting methods are called finite difference methods. Other common applications of the finite difference method are in computational science and engineering disciplines, such as thermal engineering and fluid mechanics. Also interestingly recurrence relations can be written as difference equations by replacing iteration notation with finite differences.\footnote{This is perhaps not surprising, as recurrence relations have strong similarities to differential equations. For a formalised approach to this area, see time-scale calculus, which unifies finite difference calculus and differential calculus to form a theory that can deal with systems with both continuous and discrete variables.}

\subsubsection{Accuracy of the method}

\par\hspace{4mm} In this paper we define the error as the difference between the approximation and the exact analytical solution, hence we will use simple problems with a lot of symmetry to check the accuracy of our methods. To approximate the solution to a problem when using the finite difference method the domain we want to solve over must first be quantified.\footnote{In short we want to deal with small individual parts rather than a continuous space.} Dividing the domain into a uniform grid is the usual manner of doing this. From this the finite difference method will present various discrete numerical estimations to the derivative.

\subsubsection{Approximation of second order derivative}
Consider the arbitrary function \(f(x)\). The Taylor series of this function centered at the value \(x=a\) is;

\begin{gather*}
f(x) = f(a) +(x-a)f^{(1)}(x)+\frac{(x-a)^{2}f^{(2)}(x)}{2!}+ \\
\frac{(x-a)^{3}f^{(3)}(x)}{3!}+...
\end{gather*}

Center around $x_i$ and let \(x=x_i + h\) then;

\[f(x_i+h)=f(x_i)+hf^{(1)}(x_i)+\frac{h^2f^{(2)}(x_i)}{2!}+\frac{h^3f^{(3)}(x_i)}{3!}+...\]

Similarly;

\[f(x_i-h)=f(x_i)-hf^{(1)}(x_i)+\frac{h^2f^{(2)}(x_i)}{2!}-\frac{h^3f^{(3)}(x_i)}{3!}+...\]
Therefore;

\[f(x_i+h)+f(x_i-h) = 2f(x_i) + h^2f^{(2)}(x_i) +\frac{h^4}{12}f^{(4)}(x_i)+...\]

If h is very small then only the first two terms are significant and the later terms can be ignored to yield a good approximation.

\[f(x_i+h)+f(x_i-h) \approx 2f(x_i) + h^2f^{(2)}(x_i)\]

So, by rearranging, the second order derivative of a function at \(x_i\) can be approximated by;
\[\frac{d^2f}{dx^2}\Bigg|_{x_i} = \frac{f(x_i+h)-2f(x_i)+f(x_i-h)}{h^2}\]

A similar expression can be found for functions with two variables

\[\frac{\partial^2f}{\partial x^2}\Bigg|_{x_i} = \frac{f(x_i+h,y_j)-2f(x_i,y_j)+f(x_i-h,y_j)}{h^2}\]

Note: the above expression was found by assuming $f(x,y)$ can be expressed as the product of two separate functions, one of x and one of y. \\


\subsubsection{Laplace Equation}

The Laplace equation is;
\[\nabla^2\phi = 0\]

In two dimensions this can be expressed as;
\[\frac{\partial^2\phi}{\partial x^2} + \frac{\partial^2\phi}{\partial y^2} = 0\]
Let \(x=x_i\) and \(y=y_j\) where \(x_i\) and \(y_j\) are arbitrary. Then;
\[\frac{\partial^2\phi}{\partial x^2}\Bigg|_{(x_{i},y_{j})} + \frac{\partial^2\phi}{\partial y^2}\Bigg|_{(x_{i},y_{j})} = 0\]

Using the results from the previous section this can be written;

\begin{gather*}
\frac{\phi(x_i+h,y_j)-2f(x_i,y_j)+\phi(x_i-h,y_j)}{h^2}+ \\
\frac{\phi(x_i,y_j+h)-2f(x_i,y_j)+\phi(x_i,y_j-h)}{h^2}=0
\end{gather*}

Rearranging this gives;
\begin{gather*}
\phi(x_i,y_j)=\frac{1}{4}\Bigg(\phi(x_i+h,y_j)+ \\
\phi(x_i-h,y_j)+\phi(x_i,y_j+h)+\phi(x_i,y_j-h)\Bigg)
\end{gather*}

Suppose the x-y plane was divided into a grid with lines separated by h in both the x and y direction. Let the value of \(\phi\) at an arbitrary point of the grid be denoted by \(\phi_{i,j}\), then the adjacent points in the x and y directions will be denoted \(\phi_{i\pm1,j}\) and \(\phi_{i,j\pm1}\) respectively.\\Therefore;

\begin{gather*}
\phi_{i,j}=\frac{1}{4}\Bigg(\phi_{(i+1,j)}+
\phi_{i-1,j}+\phi_{i,j+1}+\phi_{i,j-1}\Bigg)
\end{gather*}

The approximate solution to Laplace's equation at a point, provided the separation of the points is uniform and very small, is the average of the four adjacent points and so it is quite straight forward to numerically solve the Laplace equation provided there are known boundary conditions.


\subsection{Assymetric Finite Volume }


\subsection{3D algorithm}






%RESULTS- Many plots here, I imagine.
\section{Results \label{sec:res}}


Results...


%UNCERTAINTIES
\section{Uncertainties \label{sec:unc}}




%SUMMARY AND CONCLUSIONS
\section{Summary and Discussion \label{sec:sum}}


%Mostly for Adrian 
\begin{acknowledgments}
Adrian...
\end{acknowledgments}

\begin{thebibliography}{5}

\bibitem{gaugetheory1} Becchi, C., 1997, \emph{Introduction to Gauge Theories}, arXiv:hep-ph/9705211.

\bibitem{gaugetheory3} Bednyakov, V.A., Giokaris, N.D., Bednyakov, A.V., 2007, \emph{On Higgs mass generation mechanism in the Standard Model}, 	arXiv:hep-ph/0703280.

\bibitem{gaugetheory2} Brading, K., Brown, H., 2000, \emph{Noether's Theorems and Gauge Symmetries}, arXiv:hep-th/0009058.

%The following paper has a bunch of comparisons between numerical and analytical solutions... Might want
%to give it a citation in the errors part?
%\bibitem{eulerfluids} Trac, H. and Pen, U., 2002, A primer on Eulerian computational fluid dynamics for astrophysics, arXiv:astro-ph/0210611.


\end{thebibliography}



\appendix*
\section{Full analytical solution}
\section{Code}


\end{document}

